{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/nathan/anaconda3/envs/deepLearning/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential # 1 neural network pls = 1 model\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import text\n",
    "\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants\n",
    "\n",
    "img_rows, img_cols: Input image dimensions in pixels  \n",
    "in_shape: For keras (tensorflow), the dimensions of our input for a 2D convolutional layer  \n",
    "batch_size: Number of images used in each minibatch  \n",
    "nb_classes: One class per digit  \n",
    "nb_epoch: Number of times the whole data is used to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "in_shape = (img_rows, img_cols, 1)\n",
    "batch_size = 256\n",
    "nb_classes = 10\n",
    "nb_epoch = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Here we are given a set of training and testing data. We will use the training data to train the neural network, and the testing data as submission to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv').values\n",
    "test  = pd.read_csv('test.csv').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "#### Inputs (X)\n",
    "\n",
    "First we need reshape our data to be used by a Tensorflow CNN. This follows the format: (nb_of_samples, img_width, img_heigh, nb_of_color_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train[:, 1:].reshape(train.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to make sure everything is a float. Then divide it by 255 to normalize the values between [0;1] rather than [0;255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputs (Y)\n",
    "\n",
    "For the outputs, we need to get the zero'th column of train. Next we will use np_utils to one-hot-encode out vector into a binary class matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[image: 28,28 ] = [0,0,0,1,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = y_train = train[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data\n",
    "\n",
    "#### Inputs (X)\n",
    "\n",
    "For the testing data, we are not given outputs. This means that we only need to follow the reshape procedure of the training inputs (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test.reshape(test.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check shapes of all training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42000, 28, 28, 1)\n",
      "Y_train shape: (42000, 10)\n",
      "X_test shape : (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"Y_train shape: {}\".format(Y_train.shape))\n",
    "print(\"X_test shape : {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data\n",
    "\n",
    "Below we are going to visualize on of the inputs (X) for our training data to make sure it looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f180cb8af60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAFOCAYAAAARn83bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f180cb8a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(X_train[3].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Next we are going to define our convolutional neural network, we are going to use three convolution layers and two fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sequential model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(16, 3, 3, border_mode='same', input_shape=in_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 28, 28, 16)    160         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 28, 28, 16)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 14, 14, 16)    0           activation_7[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 160\n",
      "Trainable params: 160\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 28, 28, 16)    160         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 28, 28, 16)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 14, 14, 16)    0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 14, 14, 32)    4640        maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 14, 14, 32)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 7, 7, 32)      0           activation_8[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 4,800\n",
      "Trainable params: 4,800\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, 6, 4, border_mode='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 28, 28, 16)    160         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 28, 28, 16)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 14, 14, 16)    0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 14, 14, 32)    4640        maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 14, 14, 32)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 7, 7, 32)      0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 7, 7, 32)      24608       maxpooling2d_6[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 29,408\n",
      "Trainable params: 29,408\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 28, 28, 16)    160         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 28, 28, 16)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 14, 14, 16)    0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 14, 14, 32)    4640        maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 14, 14, 32)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 7, 7, 32)      0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 7, 7, 32)      24608       maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1568)          0           convolution2d_9[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 29,408\n",
      "Trainable params: 29,408\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())  # this converts our 2D feature maps to 1D feature vectors\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 28, 28, 16)    160         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 28, 28, 16)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 14, 14, 16)    0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 14, 14, 32)    4640        maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 14, 14, 32)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 7, 7, 32)      0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 7, 7, 32)      24608       maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1568)          0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1024)          1606656     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 1024)          0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1024)          0           activation_9[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 1,636,064\n",
      "Trainable params: 1,636,064\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) # helps prevent overfitting\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(nb_classes)) # nb_classes should be 10 for mnist\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .summary() allows us to peak inside our model. This allows you to see the overall structure of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 28, 28, 16)    160         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 28, 28, 16)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 14, 14, 16)    0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 14, 14, 32)    4640        maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 14, 14, 32)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 7, 7, 32)      0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 7, 7, 32)      24608       maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1568)          0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1024)          1606656     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 1024)          0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1024)          0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            10250       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 10)            0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,646,314\n",
      "Trainable params: 1,646,314\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model\n",
    "This step allows you to tell the model what optimizer you want (the thing that controls learning rate), what type of loss to use, and all other sorts of things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: the loss of the training data  \n",
    "acc: the accuracy of the training data  \n",
    "val_loss: the loss of the validation set  \n",
    "val_acc: the accuracy of the validation data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/3\n",
      "33600/33600 [==============================] - 2s - loss: 0.3936 - acc: 0.8783 - val_loss: 0.1111 - val_acc: 0.9649\n",
      "Epoch 2/3\n",
      "33600/33600 [==============================] - 1s - loss: 0.0865 - acc: 0.9742 - val_loss: 0.0654 - val_acc: 0.9783\n",
      "Epoch 3/3\n",
      "33600/33600 [==============================] - 1s - loss: 0.0546 - acc: 0.9831 - val_loss: 0.0575 - val_acc: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c167afdd8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, # specify training data\n",
    "          batch_size=batch_size, # use this many images per mini-batch - memory dependent - 256\n",
    "          nb_epoch=nb_epoch, # go through my training data this number of times - 3\n",
    "          validation_split=.2, # use 20% of the training data as validation data\n",
    "          verbose=True # please print things \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.55021382e-07,   4.81761298e-10,   9.99993324e-01,\n",
       "         5.71173041e-06,   1.58174895e-08,   1.33733358e-10,\n",
       "         2.03723843e-10,   3.31026854e-07,   4.35285557e-07,\n",
       "         1.24583668e-08], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('mnist_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('mnist_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save predictions to test file for Kaggle submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "np.savetxt('mnist-pred4.csv', np.c_[range(1,len(Y_pred)+1),Y_pred], delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deepLearning]",
   "language": "python",
   "name": "conda-env-deepLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
